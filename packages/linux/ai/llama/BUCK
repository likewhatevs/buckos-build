load("//defs:package.bzl", "package")

package(
    build_rule = "python",
    name = "llama",
    version = "2.0.0",
    url = "https://github.com/meta-llama/llama/archive/refs/tags/v2.tar.gz",
    sha256 = "a75de1dc742014a2f87055ba9a7016cae9aecf906a0094a6cb85d0d00bfd6dd6",
    description = "Meta LLaMA language model - inference code and weights",
    homepage = "https://github.com/facebookresearch/llama",
    license = "GPL-3.0",
    deps = [
        "//packages/linux/ai/ml-frameworks/fairscale:fairscale",
    ],
)
