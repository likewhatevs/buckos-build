load("@root//defs:package_defs.bzl", "python_package")

python_package(
    name = "llama-factory",
    version = "0.9.4",
    src_uri = "https://github.com/hiyouga/LLaMA-Factory/archive/refs/tags/v0.9.4.tar.gz",
    sha256 = "2ce772945da1c7c28964e23d8bae429222749a4e9df47191e2159e3f72f638fd",
    signature_required = False,
    description = "Unified Efficient Fine-Tuning of 100+ LLMs",
    homepage = "https://github.com/hiyouga/LLaMA-Factory",
    license = "Apache-2.0",
    deps = [
        "ai//ml-frameworks/transformers:transformers",
        "ai//ml-frameworks/datasets:datasets",
        "ai//ml-frameworks/accelerate:accelerate",
        "ai//ml-frameworks/peft:peft",
        "ai//ml-frameworks/trl:trl",
        "dev-libs//python/gradio:gradio",
        "dev-libs//python/matplotlib:matplotlib",
        "dev-libs//python/tyro:tyro",
        "dev-libs//python/einops:einops",
        "dev-libs//python/numpy:numpy",
        "dev-libs//python/pandas:pandas",
        "dev-libs//python/scipy:scipy",
        "dev-libs//python/sentencepiece:sentencepiece",
        "dev-libs//python/tiktoken:tiktoken",
        "dev-libs//python/modelscope:modelscope",
        "dev-libs//python/safetensors:safetensors",
        "dev-libs//python/fire:fire",
        "dev-libs//python/omegaconf:omegaconf",
        "dev-libs//python/packaging:packaging",
        "dev-libs//serialization/protobuf:protobuf",
        "dev-libs//python/pyyaml:pyyaml",
        "dev-libs//python/pydantic:pydantic",
        "dev-libs//python/uvicorn:uvicorn",
        "dev-libs//python/fastapi:fastapi",
        "dev-libs//python/sse-starlette:sse-starlette",
        "media//libraries/pyav:pyav",
        "audio//libraries/librosa:librosa",
    ],
    visibility = ["PUBLIC"],
)
